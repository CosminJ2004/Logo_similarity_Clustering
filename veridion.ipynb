{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stanbicbank.co.zw' 'astrazeneca.ua' 'autosecuritas-ct-seysses.fr'\n",
      " 'ovb.ro' 'mazda-autohaus-hellwig-hoyerswerda.de'\n",
      " 'toyota-buchreiter-eisenstadt.at' 'ebay.cn' 'greatplacetowork.com.bo'\n",
      " 'wurth-international.com' 'plameco-hannover.de']\n",
      "3416\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('logos.snappy.parquet')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "domain_names = df['domain'].dropna().unique()\n",
    "print(domain_names[:10])  \n",
    "print(domain_names.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company name from domain stanbicbank.co.zw: Stanbicbank\n",
      "Company name from domain astrazeneca.ua: Astrazeneca\n",
      "Company name from domain autosecuritas-ct-seysses.fr: Autosecuritas-ct-seysses\n",
      "Company name from domain ovb.ro: Ovb\n",
      "Company name from domain mazda-autohaus-hellwig-hoyerswerda.de: Mazda-autohaus-hellwig-hoyerswerda\n"
     ]
    }
   ],
   "source": [
    "import tldextract\n",
    "\n",
    "def extract_company_name(domain):\n",
    "    ext = tldextract.extract(domain)\n",
    "    company_name = ext.domain\n",
    "    return company_name \n",
    "\n",
    "for domain in domain_names[:5]:\n",
    "    company = extract_company_name(domain)\n",
    "    print(f\"Company name from domain {domain}: {company}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VARIANTA 1 ABANDONATA !!!\n",
    "#varianta cu API Google Cloud Service\n",
    "#Am incercat sa salvez un link cu logoul intr-un csv ca sa le accesez fara a le downloada\n",
    "#Nu am putut sa gasesc decat foarte putine linkuri cu logouri de companii de aceea am renuntat la asta\n",
    "import requests\n",
    "\n",
    "api_key = 'AIzaSyD9ycUQ4jksMgPxIECy90ocoXPjshKogBU'  \n",
    "cse_id = '9567e36e469d44f06'  \n",
    "\n",
    "def google_search(query, api_key, cse_id, num_results=1):\n",
    "    \n",
    "    url = f'https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&searchType=image&num={num_results}'\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        items = response.json().get('items', [])\n",
    "        if items:\n",
    "            return items[0]['link']\n",
    "    return None\n",
    "\n",
    "def extract_company_name(domain):\n",
    "    ext = tldextract.extract(domain)\n",
    "    company_name = ext.domain  # Extrage doar partea de domeniu (fara sufix)\n",
    "    return company_name \n",
    "def get_company_logos(company_names):\n",
    "    logos = {}\n",
    "    for company in company_names:\n",
    "        print(f\"Searching logo for: {company}\")\n",
    "        logo_url = google_search(f\"{company} logo\", api_key, cse_id)\n",
    "        if logo_url:\n",
    "            logos[company] = logo_url\n",
    "        else:\n",
    "            logos[company] = 'No logo found'\n",
    "    return logos\n",
    "company_names=[]\n",
    "for d in domain_names:\n",
    "    company_names.append(extract_company_name(d))\n",
    "\n",
    "logos = get_company_logos(company_names)\n",
    "\n",
    "# Salvam logourile intr-un fisier CSV\n",
    "output_file = 'company_logos.csv'\n",
    " \n",
    "import csv\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Company Name', 'Logo URL'])  # Header\n",
    "    for company, logo_url in logos.items():\n",
    "        writer.writerow([company, logo_url])\n",
    "\n",
    "print(f\"Logos have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Varianta implementata care a mers si am reusit sa gasesc mult mai multe logouri\n",
    "#  \n",
    "def get_company_logo(domain, folder='logos'):\n",
    "    \n",
    "    url = f\"https://logo.clearbit.com/{domain}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Salveaza logo-ul in folderul de logos\n",
    "        logo_path = os.path.join(folder, f\"{domain}_logo.png\")\n",
    "        with open(logo_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Logo-ul pentru {domain} a fost salvat în {logo_path}.\")\n",
    "    else:\n",
    "        print(f\"Nu am gasit logo pentru {domain}.\")\n",
    "for d in domain_names:\n",
    "    get_company_logo(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7840\\2391423472.py:44: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights=\"imagenet\", include_top=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mobilenetv2 incarcat.\n",
      "2900 imagini au fost procesate.\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 789ms/step\n",
      "Caracteristici extrase: (2900, 62720)\n",
      "PCA aplicat: (2900, 50)\n",
      "Clustering finalizat!\n",
      "Imaginile au fost salvate in folderele clusterelor din 'output/'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class ImageClustering:\n",
    "    def __init__(self, folder_path=\"data\", n_clusters=10, model_type=\"resnet50\", use_pca=False):\n",
    "        # Listeaza toate imaginile din folder\n",
    "        paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(('.png'))]\n",
    "        \n",
    "        self.folder_path = folder_path\n",
    "        self.n_clusters = n_clusters\n",
    "        self.use_pca = use_pca\n",
    "        self.model_type = model_type.lower()\n",
    "\n",
    "        self.image_paths = paths\n",
    "\n",
    "        #Pentru a testa pe mai multe valori a lui K\n",
    "        # Sterge folderul de output daca exista si creeaza unul nou\n",
    "        if os.path.exists(\"output\"):\n",
    "            shutil.rmtree(\"output\")\n",
    "        os.makedirs(\"output\")\n",
    "        for i in range(self.n_clusters):\n",
    "            os.makedirs(f\"output/cluster_{i}\")\n",
    "        self.model = self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        #Incarc modelul pre-antrenat pentru extragerea de caracteristici doar, nu am inclus si clasele lor (include_top=False)\n",
    "        if self.model_type == \"resnet50\":\n",
    "            base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "        elif self.model_type == \"vgg16\":\n",
    "            base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "        elif self.model_type == \"mobilenetv2\":\n",
    "          base_model = MobileNetV2(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Modelul trebuie sa fie 'resnet50' sau 'vgg16' sau 'mobilenetv2'.\")\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "        print(f\"Model {self.model_type} incarcat.\")\n",
    "        return model\n",
    "\n",
    "    def preprocess_images(self, batch_size=100):\n",
    "        # Incarca si proceseaza imaginile in batch-uri pentru a evita OOM (o problema cu care m am confruntat pentru ca nu aveam suficient RAM pentru a procesa atatea date)\n",
    "        self.images = []\n",
    "    \n",
    "        for i in range(0, len(self.image_paths), batch_size):\n",
    "            batch_paths = self.image_paths[i:i+batch_size]\n",
    "            batch_images = []\n",
    "        \n",
    "            for img_path in batch_paths:\n",
    "                try:\n",
    "                    img = image.load_img(img_path, target_size=(224, 224))\n",
    "                    img = image.img_to_array(img)\n",
    "                    img = np.expand_dims(img, axis=0)\n",
    "                    img = preprocess_input(img)\n",
    "                    batch_images.append(img)\n",
    "                except Exception as e:\n",
    "                    print(f\"Eroare la incarcarea imaginii {img_path}: {e}\")\n",
    "            \n",
    "            if batch_images:\n",
    "                batch_images = np.vstack(batch_images)  # Stack-uieste batch-ul curent\n",
    "                self.images.append(batch_images)\n",
    "        \n",
    "        self.images = np.vstack(self.images)  # Stack-uieste toate batch-urile\n",
    "        print(f\"{len(self.images)} imagini au fost procesate.\")\n",
    "\n",
    "    def extract_features(self):\n",
    "        \"\"\"Extrage caracteristicile imaginilor folosind modelul ales.\"\"\"\n",
    "        features = self.model.predict(self.images)\n",
    "        self.features = features.reshape(self.images.shape[0], -1)  # Flatten\n",
    "        print(f\"Caracteristici extrase: {self.features.shape}\")\n",
    "\n",
    "        # Aplica PCA \n",
    "        if self.use_pca:\n",
    "            pca = PCA(n_components=50, random_state=42)\n",
    "            self.features = pca.fit_transform(self.features)\n",
    "            print(f\"PCA aplicat: {self.features.shape}\")\n",
    "\n",
    "    def clustering(self):\n",
    "        \"\"\"Aplica K-Means pe caracteristicile extrase.\"\"\"\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)\n",
    "        self.labels = kmeans.fit_predict(self.features)\n",
    "        print(\"Clustering finalizat!\")\n",
    "\n",
    "    def save_clusters(self):\n",
    "        \n",
    "        for i, img_path in enumerate(self.image_paths):\n",
    "            shutil.copy(img_path, f\"output/cluster_{self.labels[i]}/\")\n",
    "        print(\"Imaginile au fost salvate in folderele clusterelor din 'output/'.\")\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        self.preprocess_images()\n",
    "        self.extract_features()\n",
    "        self.clustering()\n",
    "        self.save_clusters()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"logos\"\n",
    "    n_clusters = 40\n",
    "    model_type = \"mobilenetv2\"  # Am incercat si  resnet50 si vgg16 dar mobilenetv2 a fost mult mai light pentru resursele pe care le aveam la dispozitie\n",
    "    use_pca = True\n",
    "\n",
    "    clusterer = ImageClustering(folder_path, n_clusters, model_type, use_pca)\n",
    "    clusterer.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
